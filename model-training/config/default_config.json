{
    "batch_size": 32,
    "learning_rate": 0.001,
    "num_epochs": 100,
    "gradient_accumulation_steps": 1,
    "mixed_precision": true,
    "gradient_clipping": 1.0,
    
    "use_distributed": false,
    "use_model_parallel": false,
    "use_pipeline_parallel": false,
    "use_tensor_parallel": false,
    "num_gpus": 1,
    
    "visualization_dir": "visualizations",
    "update_interval": 5,
    "save_interval": 100,
    
    "model_type": "transformer",
    "model_config": {
        "hidden_size": 768,
        "num_attention_heads": 12,
        "num_hidden_layers": 6,
        "intermediate_size": 3072,
        "hidden_dropout_prob": 0.1,
        "attention_dropout_prob": 0.1,
        "max_position_embeddings": 512,
        "type_vocab_size": 2,
        "vocab_size": 30522
    },
    
    "data_dir": "data",
    "train_file": "train.txt",
    "eval_file": "eval.txt",
    "max_seq_length": 128,
    
    "log_dir": "logs",
    "log_level": "INFO",
    
    "theme": "default",
    "window_size": [1200, 800],
    "refresh_rate": 1.0
} 