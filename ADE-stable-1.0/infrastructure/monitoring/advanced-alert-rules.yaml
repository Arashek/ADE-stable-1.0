apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: ade-platform-advanced-alerts
  namespace: monitoring
spec:
  groups:
  - name: ade-platform-advanced
    rules:
    - alert: HighNetworkLatency
      expr: rate(http_request_duration_seconds_sum[5m]) / rate(http_request_duration_seconds_count[5m]) > 1
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: High network latency detected
        description: "Service {{ $labels.service }} has high latency: {{ $value | humanizeDuration }}"

    - alert: HighErrorRate
      expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.05
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: High error rate detected
        description: "Service {{ $labels.service }} has {{ $value | humanizePercentage }} error rate"

    - alert: GPUMemoryLeak
      expr: increase(nvidia_gpu_memory_used_bytes[1h]) > 0 and nvidia_gpu_memory_used_bytes > 0.9 * nvidia_gpu_memory_total_bytes
      for: 30m
      labels:
        severity: warning
      annotations:
        summary: Potential GPU memory leak detected
        description: "Pod {{ $labels.pod }} shows increasing GPU memory usage"

    - alert: HighDiskIO
      expr: rate(node_disk_io_time_seconds_total[5m]) > 0.8
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: High disk I/O detected
        description: "Node {{ $labels.node }} has high disk I/O: {{ $value | humanizePercentage }}"

    - alert: HighNetworkIO
      expr: rate(node_network_transmit_bytes_total[5m]) + rate(node_network_receive_bytes_total[5m]) > 1000000000
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: High network I/O detected
        description: "Node {{ $labels.node }} has high network I/O: {{ $value | humanizeBytes }}"

    - alert: ContainerOOMKilled
      expr: increase(container_memory_oom_events_total[5m]) > 0
      for: 1m
      labels:
        severity: critical
      annotations:
        summary: Container OOM killed
        description: "Container {{ $labels.container }} in pod {{ $labels.pod }} was OOM killed"

    - alert: HighGPUUtilization
      expr: avg(nvidia_gpu_utilization) by (pod) > 95
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: Critical GPU utilization
        description: "Pod {{ $labels.pod }} is using {{ $value }}% GPU"

    - alert: NodePressure
      expr: kube_node_status_condition{condition=~"MemoryPressure|DiskPressure|PIDPressure",status="true"} == 1
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: Node under pressure
        description: "Node {{ $labels.node }} is under {{ $labels.condition }}"

    - alert: PodNotScheduled
      expr: kube_pod_status_unschedulable == 1
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: Pod not scheduled
        description: "Pod {{ $labels.pod }} cannot be scheduled"

    - alert: HighPodRestartRate
      expr: rate(kube_pod_container_status_restarts_total[5m]) > 5
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: High pod restart rate
        description: "Pod {{ $labels.pod }} is restarting frequently: {{ $value }} restarts per minute"

    - alert: PersistentVolumeUsageHigh
      expr: kubelet_volume_stats_used_bytes / kubelet_volume_stats_capacity_bytes > 0.8
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: High persistent volume usage
        description: "Persistent volume {{ $labels.persistentvolumeclaim }} is using {{ $value | humanizePercentage }}"

    - alert: NodeNotReady
      expr: kube_node_status_condition{condition="Ready",status="true"} == 0
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: Node not ready
        description: "Node {{ $labels.node }} is not ready"

    - alert: HighCPUThrottling
      expr: rate(container_cpu_cfs_throttled_seconds_total[5m]) / rate(container_cpu_usage_seconds_total[5m]) > 0.2
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: High CPU throttling
        description: "Container {{ $labels.container }} in pod {{ $labels.pod }} is being throttled: {{ $value | humanizePercentage }}"

    - alert: HighMemoryThrottling
      expr: rate(container_memory_working_set_bytes[5m]) / container_spec_memory_limit_bytes > 0.9
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: High memory throttling
        description: "Container {{ $labels.container }} in pod {{ $labels.pod }} is using {{ $value | humanizePercentage }} of memory limit"

    - alert: HighNetworkErrors
      expr: rate(node_network_receive_errs_total[5m]) + rate(node_network_transmit_errs_total[5m]) > 10
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: High network errors
        description: "Node {{ $labels.node }} has {{ $value }} network errors per second"

    - alert: HighDiskErrors
      expr: rate(node_disk_read_errors_total[5m]) + rate(node_disk_write_errors_total[5m]) > 5
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: High disk errors
        description: "Node {{ $labels.node }} has {{ $value }} disk errors per second"

    - alert: HighPodEvictionRate
      expr: rate(kube_pod_status_phase{phase="Failed"}[5m]) > 2
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: High pod eviction rate
        description: "High rate of pod evictions detected: {{ $value }} pods per minute"

    - alert: HighAPILatency
      expr: rate(apiserver_request_duration_seconds_sum[5m]) / rate(apiserver_request_duration_seconds_count[5m]) > 1
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: High API server latency
        description: "API server has high latency: {{ $value | humanizeDuration }}" 