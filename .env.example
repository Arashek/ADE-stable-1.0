# Application settings
APP_URL=https://cloudev.ai
ENVIRONMENT=development
DEBUG=True

# Database settings
MONGODB_URL=mongodb://localhost:27017
MONGODB_DB=cloudev

# Email settings
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your-email@gmail.com
SMTP_PASSWORD=your-app-specific-password
FROM_EMAIL=noreply@cloudev.ai
FROM_NAME=CloudEV.ai Team

# Security settings
SECRET_KEY=your-secret-key-here

# Early access settings
MAX_WAITLIST_SIZE=1000
INVITATION_CODE_LENGTH=8
INVITATION_CODE_EXPIRY_DAYS=7

# Rate limiting
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_PERIOD=3600

# Feature flags
ENABLE_EMAIL_NOTIFICATIONS=True
ENABLE_WAITLIST=True
ENABLE_INVITATION_CODES=True

# Social media links
TWITTER_URL=https://twitter.com/cloudev
DISCORD_URL=https://discord.gg/cloudev
GITHUB_URL=https://github.com/cloudev

# Support settings
SUPPORT_EMAIL=support@cloudev.ai
SUPPORT_URL=https://support.cloudev.ai

# Database Configuration
MONGODB_URI=mongodb://mongodb:27017/ade
MONGODB_USER=admin
MONGODB_PASSWORD=your_secure_password_here

# Authentication
JWT_SECRET=your_jwt_secret_here
JWT_ALGORITHM=HS256
JWT_EXPIRATION=3600

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json

# Provider API Keys
OPENAI_API_KEY=your_openai_api_key
ANTHROPIC_API_KEY=your_anthropic_api_key
GOOGLE_API_KEY=your_google_api_key
DEEPSEEK_API_KEY=your_deepseek_api_key
GROQ_API_KEY=your_groq_api_key

# Provider Configuration
DEFAULT_PROVIDER_TIER=standard
OLLAMA_SERVER_URL=http://ollama:11434

# Model Configuration
DEFAULT_MODEL=llama2
MAX_TOKENS=1000
TEMPERATURE=0.7
TOP_P=0.9
DEFAULT_OPENAI_MODEL=gpt-4
DEFAULT_ANTHROPIC_MODEL=claude-3-opus-20240229
DEFAULT_GOOGLE_MODEL=gemini-pro

# Monitoring
ENABLE_METRICS=true
PROMETHEUS_PORT=9090
GRAFANA_PORT=3000
PROMETHEUS_MULTIPROC_DIR=/tmp

# Security
ENCRYPTION_KEY=your_encryption_key_here
API_KEY_HEADER=X-API-Key

# Redis Configuration
REDIS_URI=redis://redis:6379/0
REDIS_PASSWORD=your_secure_password_here

# Grafana Configuration
GRAFANA_ADMIN_PASSWORD=your_secure_password_here

# Performance settings
MODEL_SELECTION_STRATEGY=balanced

# API server settings
API_HOST=0.0.0.0
API_PORT=8000
API_RELOAD=False

# GitHub Configuration
GITHUB_CLIENT_ID=your_github_client_id
GITHUB_CLIENT_SECRET=your_github_client_secret
GITHUB_CALLBACK_URL=http://your-domain/auth/github/callback

# Application Settings
APP_NAME=Training Manager

# Data Directories
DATA_DIR=data
MODELS_DIR=models
LOGS_DIR=logs

# Training Settings
DEFAULT_BATCH_SIZE=32
DEFAULT_LEARNING_RATE=2e-5
DEFAULT_NUM_EPOCHS=3
DEFAULT_WARMUP_STEPS=1000
DEFAULT_WEIGHT_DECAY=0.01
DEFAULT_GRADIENT_CLIPPING=1.0

# Model Settings
DEFAULT_MODEL_TYPE=gpt2
DEFAULT_MODEL_SIZE=small
DEFAULT_MAX_LENGTH=512
DEFAULT_TEMPERATURE=0.7
DEFAULT_TOP_P=0.9

# Monitoring Settings
WANDB_PROJECT=training-manager
WANDB_ENTITY=your-username
WANDB_API_KEY=your-api-key
METRICS_UPDATE_INTERVAL=1  # seconds
RESOURCE_MONITORING_INTERVAL=5  # seconds

# System Settings
MAX_MEMORY_USAGE=0.8  # 80% of available memory
GPU_MEMORY_FRACTION=0.8  # 80% of available GPU memory
NUM_WORKERS=4
PIN_MEMORY=True

# Dataset Settings
DEFAULT_TRAIN_SPLIT=0.8
DEFAULT_VAL_SPLIT=0.1
DEFAULT_TEST_SPLIT=0.1
MAX_DATASET_SIZE=1000000  # Maximum number of samples to load

# Server Configuration
PORT=3000
NODE_ENV=development
CORS_ORIGIN=http://localhost:3000

# Security
JWT_SECRET=your-jwt-secret-key
JWT_EXPIRATION=24h

# Redis Configuration
REDIS_URL=redis://localhost:6379
REDIS_PASSWORD=

# Rate Limiting
RATE_LIMIT_MAX_REQUESTS=100
RATE_LIMIT_WINDOW_SECONDS=60

# Logging
LOG_FILE_PATH=logs/combined.log
ERROR_LOG_FILE_PATH=logs/error.log

# LLM Providers
ANTHROPIC_API_KEY=your-anthropic-api-key
OPENAI_API_KEY=your-openai-api-key

# LLM Configuration
DEFAULT_LLM_PROVIDER=claude-3-opus
FALLBACK_LLM_PROVIDER=gpt-4-turbo

# Agent Configuration
MAX_AGENTS_PER_USER=10
MAX_COLLABORATIONS_PER_AGENT=5
AGENT_TIMEOUT_SECONDS=300

# WebSocket Configuration
WS_HEARTBEAT_INTERVAL=30000
WS_CLIENT_TIMEOUT=60000

# Feature Flags
ENABLE_AGENT_COLLABORATION=true
ENABLE_LLM_FALLBACK=true
ENABLE_REAL_TIME_PREVIEW=true 